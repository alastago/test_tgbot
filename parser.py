# parser.py

import aiohttp
import asyncio
import random
import time
from html.parser import HTMLParser
from datetime import datetime
from config import SCHEDULE_URL, HTML_DUMP, LOGFILE


# =========================
# –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∫–∞–∫ –≤ –±—Ä–∞—É–∑–µ—Ä–µ
# =========================


USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
    "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 "
    "(KHTML, like Gecko) Version/16.1 Safari/605.1.15",
]

CRAWL_DELAY = 10  # –∏–∑ robots.txt

MONTHS = {
    "—è–Ω–≤–∞—Ä—è": 1, "—Ñ–µ–≤—Ä–∞–ª—è": 2, "–º–∞—Ä—Ç–∞": 3, "–∞–ø—Ä–µ–ª—è": 4,
    "–º–∞—è": 5, "–∏—é–Ω—è": 6, "–∏—é–ª—è": 7, "–∞–≤–≥—É—Å—Ç–∞": 8,
    "—Å–µ–Ω—Ç—è–±—Ä—è": 9, "–æ–∫—Ç—è–±—Ä—è": 10, "–Ω–æ—è–±—Ä—è": 11, "–¥–µ–∫–∞–±—Ä—è": 12
}

def log(text: str):
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(LOGFILE, "a", encoding="utf-8") as f:
        f.write(f"[{ts}] {text}\n")

async def warmup_session(session, headers):
    log("Session warmup: GET /")
    async with session.get(
        "https://krs.quizplease.ru/",
        headers=headers,
        timeout=20
    ) as resp:
        await resp.text()
        
def looks_like_bot_block(html: str) -> bool:
    lower = html.lower()
    checks = [
        "–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ, —á—Ç–æ –∑–∞–ø—Ä–æ—Å—ã", "captcha", "–≤—ã –Ω–µ —Ä–æ–±–æ—Ç",
        "verify", "are you human", "requests from your device look like automated"
    ]
    return any(ch in lower for ch in checks)

def parse_datetext_to_datetime(datetext: str):
    """
    datetext: '10 –¥–µ–∫–∞–±—Ä—è, –°—Ä–µ–¥–∞ –≤ 19:30'
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç datetime. –ï—Å–ª–∏ –¥–∞—Ç–∞ —É–∂–µ –ø—Ä–æ—à–ª–∞, –ø–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≥–æ–¥.
    """
    try:
        now = datetime.now()

        # –æ—Ç–¥–µ–ª—è–µ–º –¥–∞—Ç—É –æ—Ç –≤—Ä–µ–º–µ–Ω–∏
        date_part, time_part = datetext.rsplit("–≤", 1)
        date_part = date_part.strip()  # '10 –¥–µ–∫–∞–±—Ä—è, –°—Ä–µ–¥–∞'
        time_part = time_part.strip()  # '19:30'

        # –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–µ–Ω—å –∏ –º–µ—Å—è—Ü
        day_str, month_str, *_ = date_part.replace(",", "").split()
        day = int(day_str)
        month = MONTHS[month_str.lower()]

        # –∏–∑–≤–ª–µ–∫–∞–µ–º —á–∞—Å—ã –∏ –º–∏–Ω—É—Ç—ã
        hour, minute = map(int, time_part.split(":"))

        # —Å–æ–∑–¥–∞–µ–º datetime —Å —Ç–µ–∫—É—â–∏–º –≥–æ–¥–æ–º
        dt = datetime(year=now.year, month=month, day=day, hour=hour, minute=minute)

        # –µ—Å–ª–∏ –¥–∞—Ç–∞ —É–∂–µ –ø—Ä–æ—à–ª–∞, –ø–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≥–æ–¥
        if dt < now:
            dt = datetime(year=now.year + 1, month=month, day=day, hour=hour, minute=minute)

        return dt

    except Exception as e:
        log(f"Failed to parse datetext '{datetext}': {e}")
        return None




class GamesParser(HTMLParser):
    def __init__(self):
        super().__init__()
        self.games = []
        self.in_game = False
        self.current_game = {}
        self.current_field = None
        self._div_stack = 0

    def handle_starttag(self, tag, attrs):
        attrs = dict(attrs)
        if tag == "div" and "class" in attrs and "schedule-column" in attrs["class"]:
            self.in_game = True
            self._div_stack = 1
            self.current_game = {"id": attrs.get("id")}
            log(f"Found schedule-column id={attrs.get('id')}")
            return
            
        if self.in_game:
            if self.current_field == "bar" and tag == "a":
                # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ ‚Äú–ì–¥–µ —ç—Ç–æ?‚Äù
                return
            
            if tag == "div":
                self._div_stack += 1
            if tag == "div" and "class" in attrs:
                cls = attrs["class"]
                if "h2-game-card" in cls:
                    self.current_field = "title"
                elif "h3" in cls or cls.strip() == "techtext":
                    self.current_field = "datetext"
                elif "schedule-block-info-bar" in cls or "techtext techtext-halfwhite" in cls:
                    self.current_field = "bar"
                elif "price" in cls:
                    self.current_field = "price"
                else:
                    self.current_field = None
            if tag == "a" and "href" in attrs:
                href = attrs["href"]
                # –Ω–µ –ø–æ—Å–µ—â–∞–µ–º /game-page (Disallow)
                if href.startswith("/game-page"):
                    self.current_game["url"] = "https://quizplease.ru" + href

    def handle_endtag(self, tag):
        if self.in_game and tag == "div":
            self._div_stack -= 1
            if self._div_stack <= 0:
                self.in_game = False
                if "title" in self.current_game:
                    if "datetext" in self.current_game:
                        self.current_game["date"] = parse_datetext_to_datetime(self.current_game["datetext"])
                    self.games.append(self.current_game)
                    log(f"Saved game: {self.current_game.get('title')}")
                   
                self.current_game = {}
                self.current_field = None
        else:
            self.current_field = None

    def handle_data(self, data):
        if self.in_game and self.current_field:
            text = data.strip()
            if not text:
                return
    
            if self.current_field == "bar":
                # —É–¥–∞–ª—è–µ–º –ª–∏—à–Ω–µ–µ
                if text in ("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–ª–æ—â–∞–¥–∫–µ", "–ì–¥–µ —ç—Ç–æ?"):
                    return
                text = text.replace("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–ª–æ—â–∞–¥–∫–µ", "")
                text = text.replace("–ì–¥–µ —ç—Ç–æ?", "")
                text = text.strip()
    
            prev = self.current_game.get(self.current_field)
            self.current_game[self.current_field] = (prev + " " + text).strip() if prev else text

async def fetch_games():
    log("Start fetch_games()")
    headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                          "AppleWebKit/537.36 (KHTML, like Gecko) "
                          "Chrome/143.0.0.0 Safari/537.36",
        
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,"
                      "image/avif,image/webp,image/apng,*/*;q=0.8,"
                      "application/signed-exchange;v=b3;q=0.7",
        
            "Accept-Language": "en-RU,en;q=0.9,ru-RU;q=0.8,ru;q=0.7",
        
            "Accept-Encoding": "gzip, deflate, br",
        
            "Upgrade-Insecure-Requests": "1",
        
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
        
            "Referer": "https://krs.quizplease.ru/",
    }
    jar = aiohttp.CookieJar()
    jar.update_cookies({
        "city": "krs",   # üëà –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ
    })
    async with aiohttp.ClientSession(
        cookie_jar=jar,
        headers=headers
    ) as session:
        try:
            # 1Ô∏è‚É£ –ø—Ä–æ–≥—Ä–µ–≤ ‚Äî –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
            log("Warmup: GET /")
            async with session.get(
                "https://krs.quizplease.ru/",
                timeout=20
            ) as resp:
                await resp.text()
    
            await asyncio.sleep(random.uniform(1.5, 3.5))
            # 2Ô∏è‚É£ —Ä–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
            log("Fetching /schedule")
            async with session.get(SCHEDULE_URL, timeout=30) as resp:
                html = await resp.text()
                status = resp.status
        except Exception as e:
            log(f"HTTP error: {e}")
            return []

        log(f"HTTP status={status}, length={len(html)}")

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–º–ø
        try:
            with open(HTML_DUMP, "w", encoding="utf-8") as f:
                f.write(f"<!-- fetched: {datetime.utcnow().isoformat()} UTC -->\n")
                f.write(html)
            log(f"Saved HTML dump: {HTML_DUMP}")
        except Exception as e:
            log(f"Failed saving HTML dump: {e}")

        # –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫—É/–∫–∞–ø—á—É
        if status in (403, 429) or looks_like_bot_block(html):
            log("Detected bot-block/captcha, aborting parse")
            return []

        # –ø–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        parser = GamesParser()
        parser.feed(html)
        log(f"Parsed games count: {len(parser.games)}")

        # —Å–æ–±–ª—é–¥–∞–µ–º Crawl-delay
        log(f"Sleeping {CRAWL_DELAY}s to respect robots.txt")
        await asyncio.sleep(CRAWL_DELAY)

        return parser.games



